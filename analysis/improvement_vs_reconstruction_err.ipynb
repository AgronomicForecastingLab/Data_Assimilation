{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to see how percentage improvement varies with reconstruction error for AEs\n",
    "\n",
    "Hypothesis: they will be inversely correlated. \n",
    "    This experiement is more important if I do not find evidence for this hypothesis. I am just confirming that optimizing AEs to reduce reconstruction error will actually make more useful AEs. \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "from pipeline import config\n",
    "from pipeline import TrainAE, DAPipeline\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 327\n",
    "train_size = 659\n",
    "\n",
    "modes = [2, 4, 8, 16, 32, 64]\n",
    "hidden = [2, 4, 8, 16, 32, 64]\n",
    "epochs = 100\n",
    "experiment_name = \"{}_epoch_summary.pkl\".format(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size =  659\n",
      "test_size =  327\n",
      "ToyNet(\n",
      "  (fc00): Linear(in_features=100040, out_features=2, bias=True)\n",
      "  (fc01): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=100040, bias=True)\n",
      ")\n",
      "Number of parameters: 500214\n",
      "epoch [1/100], loss:151978.0470\n",
      "epoch [1/100], validation loss:83145.9388\n",
      "epoch [2/100], loss:101847.2489\n",
      "epoch [3/100], loss:84010.0258\n",
      "epoch [4/100], loss:83066.9757\n",
      "epoch [5/100], loss:83173.5554\n",
      "epoch [6/100], loss:82380.7496\n",
      "epoch [6/100], validation loss:81820.2997\n",
      "epoch [7/100], loss:82261.9105\n",
      "epoch [8/100], loss:82416.3293\n",
      "epoch [9/100], loss:81967.3657\n",
      "epoch [10/100], loss:82129.8255\n",
      "epoch [11/100], loss:81485.0364\n",
      "epoch [11/100], validation loss:81184.7706\n",
      "epoch [12/100], loss:81018.3278\n",
      "epoch [13/100], loss:81473.4401\n",
      "epoch [14/100], loss:81270.3596\n",
      "epoch [15/100], loss:80953.7102\n",
      "epoch [16/100], loss:80827.1942\n",
      "epoch [16/100], validation loss:80590.3303\n",
      "epoch [17/100], loss:80492.6206\n",
      "epoch [18/100], loss:81100.8255\n",
      "epoch [19/100], loss:80004.2489\n",
      "epoch [20/100], loss:80417.9287\n",
      "epoch [21/100], loss:80407.2686\n",
      "epoch [21/100], validation loss:79904.1774\n",
      "epoch [22/100], loss:80148.0774\n",
      "epoch [23/100], loss:80315.3263\n",
      "epoch [24/100], loss:79375.5721\n",
      "epoch [25/100], loss:79531.7739\n",
      "epoch [26/100], loss:80441.0713\n",
      "epoch [26/100], validation loss:79199.3578\n",
      "epoch [27/100], loss:79347.6206\n",
      "epoch [28/100], loss:79570.2822\n",
      "epoch [29/100], loss:78968.2049\n",
      "epoch [30/100], loss:78594.8558\n",
      "epoch [31/100], loss:78723.8346\n",
      "epoch [31/100], validation loss:78539.0765\n",
      "epoch [32/100], loss:78790.3050\n",
      "epoch [33/100], loss:78408.3126\n",
      "epoch [34/100], loss:78335.7117\n",
      "epoch [35/100], loss:78347.4325\n",
      "epoch [36/100], loss:78247.1973\n",
      "epoch [36/100], validation loss:78068.8440\n",
      "epoch [37/100], loss:77825.8149\n",
      "epoch [38/100], loss:78418.6480\n",
      "epoch [39/100], loss:78262.9287\n",
      "epoch [40/100], loss:77721.0713\n",
      "epoch [41/100], loss:77801.8528\n",
      "epoch [41/100], validation loss:77499.2355\n",
      "epoch [42/100], loss:77615.0910\n",
      "epoch [43/100], loss:77447.7678\n",
      "epoch [44/100], loss:77206.7026\n",
      "epoch [45/100], loss:77047.3050\n",
      "epoch [46/100], loss:76973.8877\n",
      "epoch [46/100], validation loss:76969.8899\n",
      "epoch [47/100], loss:76937.1002\n",
      "epoch [48/100], loss:76962.3612\n",
      "epoch [49/100], loss:76847.0637\n",
      "epoch [50/100], loss:76805.4992\n",
      "epoch [51/100], loss:76931.0319\n",
      "epoch [51/100], validation loss:76519.0887\n",
      "epoch [52/100], loss:75969.3080\n",
      "epoch [53/100], loss:76221.6737\n",
      "epoch [54/100], loss:75718.5873\n",
      "epoch [55/100], loss:76056.4947\n",
      "epoch [56/100], loss:75547.4643\n",
      "epoch [56/100], validation loss:76091.4924\n",
      "epoch [57/100], loss:76159.9879\n",
      "epoch [58/100], loss:75683.5281\n",
      "epoch [59/100], loss:75894.1351\n",
      "epoch [60/100], loss:75481.4901\n",
      "epoch [61/100], loss:75030.8907\n",
      "epoch [61/100], validation loss:75754.3303\n",
      "epoch [62/100], loss:75778.0941\n",
      "epoch [63/100], loss:74477.2747\n",
      "epoch [64/100], loss:75312.8103\n",
      "epoch [65/100], loss:75190.3718\n",
      "epoch [66/100], loss:74874.9818\n",
      "epoch [66/100], validation loss:75123.2355\n",
      "epoch [67/100], loss:75155.6419\n",
      "epoch [68/100], loss:74522.3824\n",
      "epoch [69/100], loss:75164.8558\n",
      "epoch [70/100], loss:74965.7709\n",
      "epoch [71/100], loss:74220.5812\n",
      "epoch [71/100], validation loss:74498.6972\n",
      "epoch [72/100], loss:75321.0000\n",
      "epoch [73/100], loss:74106.8756\n",
      "epoch [74/100], loss:73898.5190\n",
      "epoch [75/100], loss:74082.1684\n",
      "epoch [76/100], loss:74115.7754\n",
      "epoch [76/100], validation loss:74045.0459\n",
      "epoch [77/100], loss:73913.8741\n",
      "epoch [78/100], loss:73623.0561\n",
      "epoch [79/100], loss:73449.0212\n",
      "epoch [80/100], loss:73594.0698\n",
      "epoch [81/100], loss:73466.1305\n",
      "epoch [81/100], validation loss:73454.3180\n",
      "epoch [82/100], loss:73963.5569\n",
      "epoch [83/100], loss:73852.6525\n",
      "epoch [84/100], loss:73544.6844\n",
      "epoch [85/100], loss:73062.4325\n",
      "epoch [86/100], loss:73717.0455\n",
      "epoch [86/100], validation loss:72809.1682\n",
      "epoch [87/100], loss:73529.3111\n",
      "epoch [88/100], loss:73107.5842\n",
      "epoch [89/100], loss:72746.5645\n",
      "epoch [90/100], loss:73429.9484\n",
      "epoch [91/100], loss:72674.5584\n",
      "epoch [91/100], validation loss:72149.3700\n",
      "epoch [92/100], loss:72582.8270\n",
      "epoch [93/100], loss:71905.9469\n",
      "epoch [94/100], loss:72347.6783\n",
      "epoch [95/100], loss:72440.3900\n",
      "epoch [96/100], loss:72251.0334\n",
      "epoch [96/100], validation loss:71449.5963\n",
      "epoch [97/100], loss:72217.4992\n",
      "epoch [98/100], loss:72010.8862\n",
      "epoch [99/100], loss:72038.2898\n",
      "epoch [100/100], loss:72065.1715\n",
      "epoch [100/100], validation loss:71144.5015\n",
      "RESULTS\n",
      "Reference MAE:  2.714009776243879\n",
      "DA MAE:  4.084332084280692\n",
      "ref_MAE_mean > da_MAE_mean for 28015/100040\n",
      "If DA has worked, DA MAE > Ref_MAE\n",
      "Percentage improvement: -50.49%\n",
      "train_size =  659\n",
      "test_size =  327\n",
      "ToyNet(\n",
      "  (fc00): Linear(in_features=100040, out_features=4, bias=True)\n",
      "  (fc01): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=100040, bias=True)\n",
      ")\n",
      "Number of parameters: 900386\n",
      "epoch [1/100], loss:165539.0622\n",
      "epoch [1/100], validation loss:520263.1927\n",
      "epoch [2/100], loss:350999.4021\n",
      "epoch [3/100], loss:76998.9514\n",
      "epoch [4/100], loss:76674.4507\n",
      "epoch [5/100], loss:77111.4385\n",
      "epoch [6/100], loss:76528.6419\n",
      "epoch [6/100], validation loss:76832.7401\n",
      "epoch [7/100], loss:76389.4097\n",
      "epoch [8/100], loss:77039.3338\n",
      "epoch [9/100], loss:76770.7557\n",
      "epoch [10/100], loss:76757.5690\n",
      "epoch [11/100], loss:75944.6555\n",
      "epoch [11/100], validation loss:76628.7829\n",
      "epoch [12/100], loss:76031.0121\n",
      "epoch [13/100], loss:76332.0243\n",
      "epoch [14/100], loss:76172.6965\n",
      "epoch [15/100], loss:76325.4310\n",
      "epoch [16/100], loss:75690.4052\n",
      "epoch [16/100], validation loss:76442.6239\n",
      "epoch [17/100], loss:75724.8179\n",
      "epoch [18/100], loss:76177.8574\n",
      "epoch [19/100], loss:75640.3475\n",
      "epoch [20/100], loss:75372.4279\n",
      "epoch [21/100], loss:75669.7481\n",
      "epoch [21/100], validation loss:76323.3089\n",
      "epoch [22/100], loss:75947.9636\n",
      "epoch [23/100], loss:76150.9605\n",
      "epoch [24/100], loss:75506.5797\n",
      "epoch [25/100], loss:75443.7056\n",
      "epoch [26/100], loss:76459.7618\n",
      "epoch [26/100], validation loss:76197.4924\n",
      "epoch [27/100], loss:75875.8422\n",
      "epoch [28/100], loss:75951.6889\n",
      "epoch [29/100], loss:75808.2534\n",
      "epoch [30/100], loss:75117.8513\n",
      "epoch [31/100], loss:75509.6889\n",
      "epoch [31/100], validation loss:76076.0489\n",
      "epoch [32/100], loss:75484.6586\n",
      "epoch [33/100], loss:75124.4507\n",
      "epoch [34/100], loss:75402.6707\n",
      "epoch [35/100], loss:75328.9469\n",
      "epoch [36/100], loss:75239.4856\n",
      "epoch [36/100], validation loss:76016.1162\n",
      "epoch [37/100], loss:75027.3733\n",
      "epoch [38/100], loss:75451.1548\n",
      "epoch [39/100], loss:75054.3187\n",
      "epoch [40/100], loss:75193.6722\n",
      "epoch [41/100], loss:75469.3672\n",
      "epoch [41/100], validation loss:75811.6024\n",
      "epoch [42/100], loss:75329.1502\n",
      "epoch [43/100], loss:75038.9879\n",
      "epoch [44/100], loss:74671.2883\n",
      "epoch [45/100], loss:74833.6646\n",
      "epoch [46/100], loss:74900.9970\n",
      "epoch [46/100], validation loss:75603.9939\n",
      "epoch [47/100], loss:74683.3839\n",
      "epoch [48/100], loss:75297.7253\n",
      "epoch [49/100], loss:74917.9029\n",
      "epoch [50/100], loss:74788.1502\n",
      "epoch [51/100], loss:75390.0425\n",
      "epoch [51/100], validation loss:75403.2538\n",
      "epoch [52/100], loss:74279.2489\n",
      "epoch [53/100], loss:74844.7815\n",
      "epoch [54/100], loss:73888.0015\n",
      "epoch [55/100], loss:74791.2777\n",
      "epoch [56/100], loss:74111.5857\n",
      "epoch [56/100], validation loss:75205.3517\n",
      "epoch [57/100], loss:74625.1093\n",
      "epoch [58/100], loss:74586.8786\n",
      "epoch [59/100], loss:74656.7693\n",
      "epoch [60/100], loss:74767.0653\n",
      "epoch [61/100], loss:74027.4810\n",
      "epoch [61/100], validation loss:75002.4771\n",
      "epoch [62/100], loss:74656.0410\n",
      "epoch [63/100], loss:73499.0349\n",
      "epoch [64/100], loss:74294.5008\n",
      "epoch [65/100], loss:74251.9469\n",
      "epoch [66/100], loss:73976.3445\n",
      "epoch [66/100], validation loss:74804.2691\n",
      "epoch [67/100], loss:74744.6328\n",
      "epoch [68/100], loss:73885.9105\n",
      "epoch [69/100], loss:74855.9454\n",
      "epoch [70/100], loss:74572.0561\n",
      "epoch [71/100], loss:73997.3035\n",
      "epoch [71/100], validation loss:74620.0122\n",
      "epoch [72/100], loss:75276.9256\n",
      "epoch [73/100], loss:74212.4917\n",
      "epoch [74/100], loss:73900.4522\n",
      "epoch [75/100], loss:74001.3202\n",
      "epoch [76/100], loss:73750.2337\n",
      "epoch [76/100], validation loss:74459.7982\n",
      "epoch [77/100], loss:73999.9393\n",
      "epoch [78/100], loss:73768.2944\n",
      "epoch [79/100], loss:73658.3354\n",
      "epoch [80/100], loss:73678.9150\n",
      "epoch [81/100], loss:73901.3278\n",
      "epoch [81/100], validation loss:74378.2080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [82/100], loss:74543.0759\n",
      "epoch [83/100], loss:74318.5372\n",
      "epoch [84/100], loss:73972.9393\n",
      "epoch [85/100], loss:74024.2580\n",
      "epoch [86/100], loss:74877.4552\n",
      "epoch [86/100], validation loss:74305.3639\n",
      "epoch [87/100], loss:74540.9712\n",
      "epoch [88/100], loss:74249.8558\n",
      "epoch [89/100], loss:73451.1457\n",
      "epoch [90/100], loss:74849.5842\n",
      "epoch [91/100], loss:74173.6662\n",
      "epoch [91/100], validation loss:74242.7584\n",
      "epoch [92/100], loss:73775.8741\n",
      "epoch [93/100], loss:73321.4522\n",
      "epoch [94/100], loss:73683.3672\n",
      "epoch [95/100], loss:74003.2640\n",
      "epoch [96/100], loss:72977.7876\n",
      "epoch [96/100], validation loss:74174.0306\n",
      "epoch [97/100], loss:73559.4370\n",
      "epoch [98/100], loss:73752.4917\n",
      "epoch [99/100], loss:73788.0425\n",
      "epoch [100/100], loss:73756.1548\n",
      "epoch [100/100], validation loss:74065.3761\n",
      "RESULTS\n",
      "Reference MAE:  2.714009776243879\n",
      "DA MAE:  2.703071692340854\n",
      "ref_MAE_mean > da_MAE_mean for 53989/100040\n",
      "If DA has worked, DA MAE > Ref_MAE\n",
      "Percentage improvement: 0.40%\n",
      "train_size =  659\n",
      "test_size =  327\n",
      "ToyNet(\n",
      "  (fc00): Linear(in_features=100040, out_features=8, bias=True)\n",
      "  (fc01): Linear(in_features=8, out_features=2, bias=True)\n",
      "  (fc1): Linear(in_features=2, out_features=8, bias=True)\n",
      "  (fc2): Linear(in_features=8, out_features=100040, bias=True)\n",
      ")\n",
      "Number of parameters: 1700730\n",
      "epoch [1/100], loss:246495.1684\n",
      "epoch [1/100], validation loss:541702.2141\n",
      "epoch [2/100], loss:434573.2686\n",
      "epoch [3/100], loss:503574.7344\n",
      "epoch [4/100], loss:322009.2564\n",
      "epoch [5/100], loss:227401.3111\n",
      "epoch [6/100], loss:217976.3217\n",
      "epoch [6/100], validation loss:174387.0214\n",
      "epoch [7/100], loss:156605.4082\n",
      "epoch [8/100], loss:189051.2413\n",
      "epoch [9/100], loss:148316.0395\n",
      "epoch [10/100], loss:121797.8543\n",
      "epoch [11/100], loss:117287.4962\n",
      "epoch [11/100], validation loss:122568.2324\n",
      "epoch [12/100], loss:112597.2701\n",
      "epoch [13/100], loss:105536.1062\n",
      "epoch [14/100], loss:83113.9863\n",
      "epoch [15/100], loss:83250.2261\n",
      "epoch [16/100], loss:86384.2109\n",
      "epoch [16/100], validation loss:99934.3731\n",
      "epoch [17/100], loss:88912.0470\n",
      "epoch [18/100], loss:89548.2989\n",
      "epoch [19/100], loss:92648.5478\n",
      "epoch [20/100], loss:92468.4856\n",
      "epoch [21/100], loss:98867.4841\n",
      "epoch [21/100], validation loss:101467.5229\n",
      "epoch [22/100], loss:90679.7830\n",
      "epoch [23/100], loss:97377.1639\n",
      "epoch [24/100], loss:87739.6980\n",
      "epoch [25/100], loss:93251.5402\n",
      "epoch [26/100], loss:87481.8589\n",
      "epoch [26/100], validation loss:97702.0917\n",
      "epoch [27/100], loss:87494.7117\n",
      "epoch [28/100], loss:87540.0759\n",
      "epoch [29/100], loss:89844.0197\n",
      "epoch [30/100], loss:93845.2489\n",
      "epoch [31/100], loss:93071.3460\n",
      "epoch [31/100], validation loss:83026.6055\n",
      "epoch [32/100], loss:80936.0516\n",
      "epoch [33/100], loss:76026.5190\n",
      "epoch [34/100], loss:75446.7860\n",
      "epoch [35/100], loss:75368.4992\n",
      "epoch [36/100], loss:75769.9530\n",
      "epoch [36/100], validation loss:75229.8777\n",
      "epoch [37/100], loss:74909.2504\n",
      "epoch [38/100], loss:74686.0015\n",
      "epoch [39/100], loss:74107.0455\n",
      "epoch [40/100], loss:73358.5372\n",
      "epoch [41/100], loss:73636.7709\n",
      "epoch [41/100], validation loss:72000.1101\n",
      "epoch [42/100], loss:73335.8695\n",
      "epoch [43/100], loss:73304.5083\n",
      "epoch [44/100], loss:73178.4340\n",
      "epoch [45/100], loss:72877.1077\n",
      "epoch [46/100], loss:72006.6707\n",
      "epoch [46/100], validation loss:71084.8746\n",
      "epoch [47/100], loss:71536.2610\n",
      "epoch [48/100], loss:71858.3748\n",
      "epoch [49/100], loss:72565.6161\n",
      "epoch [50/100], loss:71412.0061\n",
      "epoch [51/100], loss:72006.0789\n",
      "epoch [51/100], validation loss:70675.2049\n",
      "epoch [52/100], loss:70652.4416\n",
      "epoch [53/100], loss:70563.5478\n",
      "epoch [54/100], loss:70443.3293\n",
      "epoch [55/100], loss:70934.6859\n",
      "epoch [56/100], loss:69111.4401\n",
      "epoch [56/100], validation loss:67032.1590\n",
      "epoch [57/100], loss:68132.5903\n",
      "epoch [58/100], loss:67696.9894\n",
      "epoch [59/100], loss:67599.1168\n",
      "epoch [60/100], loss:67675.2944\n",
      "epoch [61/100], loss:66892.3885\n",
      "epoch [61/100], validation loss:64697.8043\n",
      "epoch [62/100], loss:67946.1791\n",
      "epoch [63/100], loss:69282.1108\n",
      "epoch [64/100], loss:68567.9469\n",
      "epoch [65/100], loss:69532.4082\n",
      "epoch [66/100], loss:68199.1654\n",
      "epoch [66/100], validation loss:67382.8930\n",
      "epoch [67/100], loss:68762.7709\n",
      "epoch [68/100], loss:67930.3278\n",
      "epoch [69/100], loss:67363.7026\n",
      "epoch [70/100], loss:68942.9241\n",
      "epoch [71/100], loss:66098.4947\n",
      "epoch [71/100], validation loss:63076.9541\n",
      "epoch [72/100], loss:67370.7511\n",
      "epoch [73/100], loss:67161.3354\n",
      "epoch [74/100], loss:67616.2974\n",
      "epoch [75/100], loss:64588.1411\n",
      "epoch [76/100], loss:64448.9909\n",
      "epoch [76/100], validation loss:58137.4557\n",
      "epoch [77/100], loss:62360.9150\n",
      "epoch [78/100], loss:64112.9939\n",
      "epoch [79/100], loss:63589.9803\n",
      "epoch [80/100], loss:62087.0516\n",
      "epoch [81/100], loss:66242.0273\n",
      "epoch [81/100], validation loss:70426.1774\n",
      "epoch [82/100], loss:71289.8741\n",
      "epoch [83/100], loss:75393.6768\n",
      "epoch [84/100], loss:84666.3020\n",
      "epoch [85/100], loss:90377.5235\n",
      "epoch [86/100], loss:74837.2018\n",
      "epoch [86/100], validation loss:80211.0214\n",
      "epoch [87/100], loss:74147.6070\n",
      "epoch [88/100], loss:90295.5781\n",
      "epoch [89/100], loss:100650.4401\n",
      "epoch [90/100], loss:80209.8225\n",
      "epoch [91/100], loss:61021.0819\n",
      "epoch [91/100], validation loss:63292.8073\n",
      "epoch [92/100], loss:64345.9408\n",
      "epoch [93/100], loss:69501.7602\n",
      "epoch [94/100], loss:73563.0561\n",
      "epoch [95/100], loss:67553.2853\n",
      "epoch [96/100], loss:60880.0744\n",
      "epoch [96/100], validation loss:58321.1560\n",
      "epoch [97/100], loss:58350.8422\n",
      "epoch [98/100], loss:55881.8923\n",
      "epoch [99/100], loss:56184.9605\n",
      "epoch [100/100], loss:53938.6388\n",
      "epoch [100/100], validation loss:53824.3058\n",
      "RESULTS\n",
      "Reference MAE:  2.714009776243879\n",
      "DA MAE:  3.372357776915992\n",
      "ref_MAE_mean > da_MAE_mean for 33385/100040\n",
      "If DA has worked, DA MAE > Ref_MAE\n",
      "Percentage improvement: -24.26%\n",
      "train_size =  659\n",
      "test_size =  327\n",
      "ToyNet(\n",
      "  (fc00): Linear(in_features=100040, out_features=16, bias=True)\n",
      "  (fc01): Linear(in_features=16, out_features=2, bias=True)\n",
      "  (fc1): Linear(in_features=2, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=100040, bias=True)\n",
      ")\n",
      "Number of parameters: 3301418\n",
      "epoch [1/100], loss:293823.5933\n",
      "epoch [1/100], validation loss:417065.4924\n",
      "epoch [2/100], loss:311080.4249\n",
      "epoch [3/100], loss:237390.3369\n",
      "epoch [4/100], loss:144261.0986\n",
      "epoch [5/100], loss:121102.9772\n",
      "epoch [6/100], loss:136575.2959\n",
      "epoch [6/100], validation loss:139458.4954\n",
      "epoch [7/100], loss:133949.4294\n",
      "epoch [8/100], loss:103925.1244\n",
      "epoch [9/100], loss:108031.0622\n",
      "epoch [10/100], loss:95697.7618\n",
      "epoch [11/100], loss:89174.7269\n",
      "epoch [11/100], validation loss:98480.6422\n",
      "epoch [12/100], loss:88957.2443\n",
      "epoch [13/100], loss:89871.0653\n",
      "epoch [14/100], loss:80335.9423\n",
      "epoch [15/100], loss:81908.2033\n",
      "epoch [16/100], loss:81436.8786\n",
      "epoch [16/100], validation loss:76318.1407\n",
      "epoch [17/100], loss:75390.1745\n",
      "epoch [18/100], loss:78988.5387\n",
      "epoch [19/100], loss:77636.7769\n",
      "epoch [20/100], loss:74541.8907\n",
      "epoch [21/100], loss:76698.7618\n",
      "epoch [21/100], validation loss:74182.8440\n",
      "epoch [22/100], loss:75398.9105\n",
      "epoch [23/100], loss:75303.3581\n",
      "epoch [24/100], loss:75777.4765\n",
      "epoch [25/100], loss:73872.1973\n",
      "epoch [26/100], loss:74375.8923\n",
      "epoch [26/100], validation loss:73113.1254\n",
      "epoch [27/100], loss:73583.3035\n",
      "epoch [28/100], loss:73344.0622\n",
      "epoch [29/100], loss:72665.5144\n",
      "epoch [30/100], loss:72281.1806\n",
      "epoch [31/100], loss:71641.1973\n",
      "epoch [31/100], validation loss:70128.7829\n",
      "epoch [32/100], loss:71024.3915\n",
      "epoch [33/100], loss:70043.5736\n",
      "epoch [34/100], loss:70208.4507\n",
      "epoch [35/100], loss:69050.0121\n",
      "epoch [36/100], loss:68467.1062\n",
      "epoch [36/100], validation loss:66976.6972\n",
      "epoch [37/100], loss:69405.8725\n",
      "epoch [38/100], loss:70563.4052\n",
      "epoch [39/100], loss:72412.7860\n",
      "epoch [40/100], loss:77789.9879\n",
      "epoch [41/100], loss:74016.3505\n",
      "epoch [41/100], validation loss:61303.6881\n",
      "epoch [42/100], loss:74458.5432\n",
      "epoch [43/100], loss:79666.0030\n",
      "epoch [44/100], loss:70449.5766\n",
      "epoch [45/100], loss:64538.5948\n",
      "epoch [46/100], loss:81495.3809\n",
      "epoch [46/100], validation loss:60178.2385\n",
      "epoch [47/100], loss:76074.8300\n",
      "epoch [48/100], loss:81040.5281\n",
      "epoch [49/100], loss:76866.4765\n",
      "epoch [50/100], loss:96070.1851\n",
      "epoch [51/100], loss:79786.0197\n",
      "epoch [51/100], validation loss:71163.5780\n",
      "epoch [52/100], loss:68205.6313\n",
      "epoch [53/100], loss:72392.4355\n",
      "epoch [54/100], loss:65490.8816\n",
      "epoch [55/100], loss:61156.8543\n",
      "epoch [56/100], loss:60277.4158\n",
      "epoch [56/100], validation loss:59833.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [57/100], loss:59100.8900\n",
      "epoch [58/100], loss:57041.9719\n",
      "epoch [59/100], loss:55064.3247\n",
      "epoch [60/100], loss:49703.5516\n",
      "epoch [61/100], loss:48818.7390\n",
      "epoch [61/100], validation loss:45146.0306\n",
      "epoch [62/100], loss:47427.2671\n",
      "epoch [63/100], loss:51983.8801\n",
      "epoch [64/100], loss:48917.6237\n",
      "epoch [65/100], loss:43845.9264\n",
      "epoch [66/100], loss:42697.4545\n",
      "epoch [66/100], validation loss:45130.1070\n",
      "epoch [67/100], loss:41029.2557\n",
      "epoch [68/100], loss:37752.1684\n",
      "epoch [69/100], loss:40258.4090\n",
      "epoch [70/100], loss:49770.6775\n",
      "epoch [71/100], loss:58091.1700\n",
      "epoch [71/100], validation loss:105297.0520\n",
      "epoch [72/100], loss:88125.3460\n",
      "epoch [73/100], loss:79052.1320\n",
      "epoch [74/100], loss:82633.0395\n",
      "epoch [75/100], loss:96472.1335\n",
      "epoch [76/100], loss:56719.9788\n",
      "epoch [76/100], validation loss:65557.0092\n",
      "epoch [77/100], loss:55128.0023\n",
      "epoch [78/100], loss:53203.9780\n",
      "epoch [79/100], loss:40998.3945\n",
      "epoch [80/100], loss:35674.6404\n",
      "epoch [81/100], loss:34883.4666\n",
      "epoch [81/100], validation loss:27682.0275\n",
      "epoch [82/100], loss:29717.9461\n",
      "epoch [83/100], loss:33589.2064\n",
      "epoch [84/100], loss:32329.6077\n",
      "epoch [85/100], loss:25976.8915\n",
      "epoch [86/100], loss:24229.0713\n",
      "epoch [86/100], validation loss:25384.0413\n",
      "epoch [87/100], loss:24763.2041\n",
      "epoch [88/100], loss:28511.3949\n",
      "epoch [89/100], loss:30964.2083\n",
      "epoch [90/100], loss:32637.6176\n",
      "epoch [91/100], loss:26374.1760\n",
      "epoch [91/100], validation loss:17593.9174\n",
      "epoch [92/100], loss:24394.0725\n",
      "epoch [93/100], loss:25041.1161\n",
      "epoch [94/100], loss:26249.8942\n",
      "epoch [95/100], loss:25077.8949\n",
      "epoch [96/100], loss:23537.8983\n",
      "epoch [96/100], validation loss:14538.2278\n",
      "epoch [97/100], loss:18439.9211\n",
      "epoch [98/100], loss:19215.0102\n",
      "epoch [99/100], loss:19190.6737\n",
      "epoch [100/100], loss:25243.9325\n",
      "epoch [100/100], validation loss:36468.4709\n",
      "RESULTS\n",
      "Reference MAE:  2.714009776243879\n",
      "DA MAE:  1.741335271290295\n",
      "ref_MAE_mean > da_MAE_mean for 75752/100040\n",
      "If DA has worked, DA MAE > Ref_MAE\n",
      "Percentage improvement: 35.84%\n",
      "train_size =  659\n",
      "test_size =  327\n",
      "ToyNet(\n",
      "  (fc00): Linear(in_features=100040, out_features=32, bias=True)\n",
      "  (fc01): Linear(in_features=32, out_features=2, bias=True)\n",
      "  (fc1): Linear(in_features=2, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=100040, bias=True)\n",
      ")\n",
      "Number of parameters: 6502794\n",
      "epoch [1/100], loss:417964.0486\n",
      "epoch [1/100], validation loss:651619.9144\n",
      "epoch [2/100], loss:437895.5994\n",
      "epoch [3/100], loss:423656.5281\n",
      "epoch [4/100], loss:174703.0470\n",
      "epoch [5/100], loss:236781.5357\n",
      "epoch [6/100], loss:205381.6449\n",
      "epoch [6/100], validation loss:210094.5321\n",
      "epoch [7/100], loss:163850.0334\n",
      "epoch [8/100], loss:189546.3156\n",
      "epoch [9/100], loss:145330.0850\n",
      "epoch [10/100], loss:136228.9712\n",
      "epoch [11/100], loss:123702.8725\n",
      "epoch [11/100], validation loss:130261.6024\n",
      "epoch [12/100], loss:112311.5524\n",
      "epoch [13/100], loss:102756.9939\n",
      "epoch [14/100], loss:86140.0061\n",
      "epoch [15/100], loss:87803.9697\n",
      "epoch [16/100], loss:78031.2231\n",
      "epoch [16/100], validation loss:81986.3486\n",
      "epoch [17/100], loss:80246.1578\n",
      "epoch [18/100], loss:76293.4522\n",
      "epoch [19/100], loss:77490.5402\n",
      "epoch [20/100], loss:73319.7299\n",
      "epoch [21/100], loss:72883.8786\n",
      "epoch [21/100], validation loss:73319.9755\n",
      "epoch [22/100], loss:73018.4294\n",
      "epoch [23/100], loss:72630.1897\n",
      "epoch [24/100], loss:71859.1275\n",
      "epoch [25/100], loss:70741.0121\n",
      "epoch [26/100], loss:70587.4021\n",
      "epoch [26/100], validation loss:67247.9144\n",
      "epoch [27/100], loss:68946.7390\n",
      "epoch [28/100], loss:67325.2777\n",
      "epoch [29/100], loss:65525.1472\n",
      "epoch [30/100], loss:63787.4810\n",
      "epoch [31/100], loss:60422.1654\n",
      "epoch [31/100], validation loss:56314.6239\n",
      "epoch [32/100], loss:58115.5918\n",
      "epoch [33/100], loss:56339.9165\n",
      "epoch [34/100], loss:58268.9954\n",
      "epoch [35/100], loss:60665.4962\n",
      "epoch [36/100], loss:63373.8680\n",
      "epoch [36/100], validation loss:77588.1162\n",
      "epoch [37/100], loss:81818.0486\n",
      "epoch [38/100], loss:91844.2382\n",
      "epoch [39/100], loss:112410.6965\n",
      "epoch [40/100], loss:89454.0956\n",
      "epoch [41/100], loss:108951.9226\n",
      "epoch [41/100], validation loss:126557.2110\n",
      "epoch [42/100], loss:105121.8171\n",
      "epoch [43/100], loss:102500.9605\n",
      "epoch [44/100], loss:78688.3369\n",
      "epoch [45/100], loss:69237.9848\n",
      "epoch [46/100], loss:70199.3429\n",
      "epoch [46/100], validation loss:71700.2813\n",
      "epoch [47/100], loss:74148.9788\n",
      "epoch [48/100], loss:58637.1138\n",
      "epoch [49/100], loss:65189.3141\n",
      "epoch [50/100], loss:47411.7906\n",
      "epoch [51/100], loss:51821.4583\n",
      "epoch [51/100], validation loss:45715.5719\n",
      "epoch [52/100], loss:42152.8703\n",
      "epoch [53/100], loss:51015.9454\n",
      "epoch [54/100], loss:52759.8528\n",
      "epoch [55/100], loss:44117.9279\n",
      "epoch [56/100], loss:36685.2580\n",
      "epoch [56/100], validation loss:32641.5810\n",
      "epoch [57/100], loss:33544.2735\n",
      "epoch [58/100], loss:29303.3467\n",
      "epoch [59/100], loss:24808.6055\n",
      "epoch [60/100], loss:23530.0376\n",
      "epoch [61/100], loss:23818.3790\n",
      "epoch [61/100], validation loss:24380.4557\n",
      "epoch [62/100], loss:22916.9784\n",
      "epoch [63/100], loss:23558.4913\n",
      "epoch [64/100], loss:24902.9006\n",
      "epoch [65/100], loss:24504.5550\n",
      "epoch [66/100], loss:21236.5933\n",
      "epoch [66/100], validation loss:17674.4694\n",
      "epoch [67/100], loss:19580.7394\n",
      "epoch [68/100], loss:18703.1847\n",
      "epoch [69/100], loss:19561.7841\n",
      "epoch [70/100], loss:18125.9594\n",
      "epoch [71/100], loss:18265.0520\n",
      "epoch [71/100], validation loss:14014.7936\n",
      "epoch [72/100], loss:17215.5649\n",
      "epoch [73/100], loss:17498.4044\n",
      "epoch [74/100], loss:15932.6590\n",
      "epoch [75/100], loss:15218.2079\n",
      "epoch [76/100], loss:15870.2253\n",
      "epoch [76/100], validation loss:15400.4725\n",
      "epoch [77/100], loss:16560.6939\n",
      "epoch [78/100], loss:14888.0444\n",
      "epoch [79/100], loss:16122.5584\n",
      "epoch [80/100], loss:17271.7948\n",
      "epoch [81/100], loss:17457.8122\n",
      "epoch [81/100], validation loss:13687.3609\n",
      "epoch [82/100], loss:16171.6214\n",
      "epoch [83/100], loss:18751.6719\n",
      "epoch [84/100], loss:19243.0277\n",
      "epoch [85/100], loss:18849.7959\n",
      "epoch [86/100], loss:18579.2728\n",
      "epoch [86/100], validation loss:13779.8761\n",
      "epoch [87/100], loss:17593.1434\n",
      "epoch [88/100], loss:17169.9260\n",
      "epoch [89/100], loss:15948.2261\n",
      "epoch [90/100], loss:15189.9177\n",
      "epoch [91/100], loss:15428.1529\n",
      "epoch [91/100], validation loss:12956.7141\n",
      "epoch [92/100], loss:15619.6149\n",
      "epoch [93/100], loss:15036.1343\n",
      "epoch [94/100], loss:14606.5195\n",
      "epoch [95/100], loss:14598.2356\n",
      "epoch [96/100], loss:14033.0171\n",
      "epoch [96/100], validation loss:11608.4671\n",
      "epoch [97/100], loss:14241.1692\n",
      "epoch [98/100], loss:15140.0205\n",
      "epoch [99/100], loss:15785.0812\n",
      "epoch [100/100], loss:14682.0696\n",
      "epoch [100/100], validation loss:10679.5206\n",
      "RESULTS\n",
      "Reference MAE:  2.714009776243879\n",
      "DA MAE:  2.8673836036007803\n",
      "ref_MAE_mean > da_MAE_mean for 43030/100040\n",
      "If DA has worked, DA MAE > Ref_MAE\n",
      "Percentage improvement: -5.65%\n",
      "train_size =  659\n",
      "test_size =  327\n",
      "ToyNet(\n",
      "  (fc00): Linear(in_features=100040, out_features=64, bias=True)\n",
      "  (fc01): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (fc1): Linear(in_features=2, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=100040, bias=True)\n",
      ")\n",
      "Number of parameters: 12905546\n",
      "epoch [1/100], loss:402365.0076\n",
      "epoch [1/100], validation loss:969017.0520\n",
      "epoch [2/100], loss:647288.5615\n",
      "epoch [3/100], loss:443144.8801\n",
      "epoch [4/100], loss:203856.4704\n",
      "epoch [5/100], loss:246965.1229\n",
      "epoch [6/100], loss:163156.2914\n",
      "epoch [6/100], validation loss:242878.9725\n",
      "epoch [7/100], loss:187336.5979\n",
      "epoch [8/100], loss:194977.0895\n",
      "epoch [9/100], loss:141658.4613\n",
      "epoch [10/100], loss:104931.2686\n",
      "epoch [11/100], loss:115660.4643\n",
      "epoch [11/100], validation loss:88833.2722\n",
      "epoch [12/100], loss:88454.1791\n",
      "epoch [13/100], loss:83693.5948\n",
      "epoch [14/100], loss:75412.9848\n",
      "epoch [15/100], loss:77596.2428\n",
      "epoch [16/100], loss:68606.2534\n",
      "epoch [16/100], validation loss:69241.7431\n",
      "epoch [17/100], loss:66722.7284\n",
      "epoch [18/100], loss:62553.0273\n",
      "epoch [19/100], loss:59511.7041\n",
      "epoch [20/100], loss:59378.7185\n",
      "epoch [21/100], loss:66741.2595\n",
      "epoch [21/100], validation loss:104198.1040\n",
      "epoch [22/100], loss:87798.5994\n",
      "epoch [23/100], loss:95523.0501\n",
      "epoch [24/100], loss:59380.9954\n",
      "epoch [25/100], loss:51920.7511\n",
      "epoch [26/100], loss:58201.9241\n",
      "epoch [26/100], validation loss:64171.1009\n",
      "epoch [27/100], loss:61854.6396\n",
      "epoch [28/100], loss:61636.9651\n",
      "epoch [29/100], loss:61427.7534\n",
      "epoch [30/100], loss:59334.7640\n",
      "epoch [31/100], loss:50913.1328\n",
      "epoch [31/100], validation loss:27873.0734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [32/100], loss:38255.7686\n",
      "epoch [33/100], loss:38877.7504\n",
      "epoch [34/100], loss:32936.8930\n",
      "epoch [35/100], loss:29374.2527\n",
      "epoch [36/100], loss:30341.6753\n",
      "epoch [36/100], validation loss:26225.2783\n",
      "epoch [37/100], loss:28342.7466\n",
      "epoch [38/100], loss:30448.8888\n",
      "epoch [39/100], loss:32659.2049\n",
      "epoch [40/100], loss:30100.8737\n",
      "epoch [41/100], loss:32568.8050\n",
      "epoch [41/100], validation loss:35206.3180\n",
      "epoch [42/100], loss:33236.0964\n",
      "epoch [43/100], loss:30127.6927\n",
      "epoch [44/100], loss:34301.2489\n",
      "epoch [45/100], loss:25614.6115\n",
      "epoch [46/100], loss:29603.8088\n",
      "epoch [46/100], validation loss:34375.0917\n",
      "epoch [47/100], loss:29740.7989\n",
      "epoch [48/100], loss:32375.6927\n",
      "epoch [49/100], loss:38821.9514\n",
      "epoch [50/100], loss:29880.5542\n",
      "epoch [51/100], loss:31926.8118\n",
      "epoch [51/100], validation loss:21418.1422\n",
      "epoch [52/100], loss:27360.4499\n",
      "epoch [53/100], loss:28754.1965\n",
      "epoch [54/100], loss:32951.0592\n",
      "epoch [55/100], loss:29499.6768\n",
      "epoch [56/100], loss:23254.9370\n",
      "epoch [56/100], validation loss:20700.0749\n",
      "epoch [57/100], loss:21997.0175\n",
      "epoch [58/100], loss:19197.8968\n",
      "epoch [59/100], loss:19112.0592\n"
     ]
    }
   ],
   "source": [
    "settings = config.ToyAEConfig()\n",
    "settings.DEBUG = False\n",
    "\n",
    "mode_vals = []\n",
    "hid_vals = []\n",
    "recon_errs_valid = []\n",
    "recon_errs_train = []\n",
    "refMA_means = []\n",
    "daMA_means = []\n",
    "percent_improve_vals = []\n",
    "\n",
    "for mode in modes:\n",
    "    settings.NUMBER_MODES = mode\n",
    "    for hid in hidden:\n",
    "        settings.HIDDEN = hid\n",
    "        settings.kwargs = {\"inn\":mode, \"hid\":hid, \"out\": settings.n}\n",
    "\n",
    "        trainer = TrainAE(settings)\n",
    "        model = trainer.train(epochs)\n",
    "        DA = DAPipeline()\n",
    "        _, stats = DA.Var_DA_routine(settings, return_stats = True)\n",
    "        \n",
    "        \n",
    "        results_fp_train = settings.RESULTS_FP + \"toy_train_mode{}_hid{}.txt\".format(settings.NUMBER_MODES, settings.HIDDEN)\n",
    "        results_fp_test = settings.RESULTS_FP + \"toy_test_mode{}_hid{}.txt\".format(settings.NUMBER_MODES, settings.HIDDEN)\n",
    "        with open(results_fp_train, 'rb') as fp:\n",
    "            train_data = pickle.load(fp)\n",
    "        with open(results_fp_test, 'rb') as fp:\n",
    "            test_data = pickle.load(fp)\n",
    "        \n",
    "        mode_vals.append(mode)\n",
    "        hid_vals.append(hid)\n",
    "        recon_errs_valid.append(test_data[-1][1])\n",
    "        recon_errs_train.append(train_data[-1][1])\n",
    "        percent_improve_vals.append(stats[\"Percent_improvement\"])\n",
    "        refMA_means.append(stats[\"ref_MAE_mean\"])\n",
    "        daMA_means.append(stats[\"da_MAE_mean\"])\n",
    "        \n",
    "data = {\"mode_vals\": mode_vals,\n",
    "    \"hid_vals\": hid_vals,\n",
    "    \"recon_errs_valid\": recon_errs_valid,\n",
    "    \"recon_errs_train\": recon_errs_train,\n",
    "    \"refMA_means\": refMA_means,\n",
    "    \"daMA_means\": daMA_means,\n",
    "    \"percent_improve_vals\": percent_improve_vals}\n",
    "df = pd.DataFrame(data)\n",
    "fp = settings.RESULTS_FP +  experiment_name\n",
    "df.to_pickle(fp) \n",
    "\n",
    "df2 = pd.read_pickle(fp)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df2[\"percent_improve_vals\"], df2[\"recon_errs_valid\"] )\n",
    "plt.xlabel(\"percent improvement\")\n",
    "plt.ylabel(\"Reconstruction Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 889482.0795107033), (1, 366328.41590214067)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
